<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
    <title>Sheikh GPT</title>
</head>

<body style="display: block; text-align: left;">
    <div class="article-image">
    <img src="images/Eng_07.png" alt="Article Image" style="max-width: 100%;" class="enlargeable-image">
</div>
    
    <article class="article-content">
        <p>In the first article entitled <i>The Challenge of Science & Technology,</i> it is explained that this hadith refers to artificial intelligence (AI). From the whip to the thigh that speaks, this hadith may be alluding to the advancement of AI technology that is beginning to unfold in our time. What the Prophet ﷺ mentioned could potentially occur in a literal sense when this technology reaches full maturity—alongside developments in quantum and neurological sciences—in the near future. الله أعلم.</p>
<p class="centered-paragraph">* * *</p>
        <p>What is to be focused on here is a growing issue that has only recently emerged, one that could potentially bring disastrous consequences to our community—“Sheikh GPT.” This refers to the misuse of generative AI, where people have started to rely on tools like ChatGPT, Grok, or Gemini as their religious reference. In fact, there are already instances where religious content is being generated entirely using these AI tools, with the intention of using it for preaching. I have witnessed it firsthand.</p>
        <p>We cannot deny the benefits of this technology. In fact, I personally use it myself. As someone balancing work and conducting in-depth research on religious studies, AI has been immensely helpful in producing articles and videos related to Islam. However, I use it only in moderation and for the tasks it is suited for, such as website development, refining English translations, and using AI voice narrators. All of this helps save time, effort, and money, especially for those of us who are less financially fortunate.</p>
        <p>The first article and video also warned about the fitna that some branches of science and technology may bring. And the meaning of “fitna” in Classical Arabic was further elaborated in the article titled <i>Fitna.</i> In the context of “Sheikh GPT,” fitna arises from a lack of knowledge in science and technology, as well as a lack of understanding of religious knowledge. In Verse 36 of Surah al-Isra, Allah (SWT) says:</p>
<h4>وَلَا تَقۡفُ مَا لَيۡسَ لَكَ بِهِۦ عِلۡمٌۚ</h4>
<p class="centered-paragraph"><b>Do not follow what you have no (sure) knowledge of.</b></p>
        <p>This Verse teaches us the importance of equipping ourselves with sufficient knowledge before engaging in any matter. We should avoid acting hastily, for as Rasulullah ﷺ said in <i>Musnad Abi Ya’la</i> 4256, haste is from Satan. Additionally, the Quranic Verse reminds us that our hearing, sight, and hearts will be held accountable.</p>
        <p>To those who have elevated generative AI as their “sheikh,” ask yourself these three questions. First: Do you truly understand the characteristics of generative AI to the point that you would trust it as a reliable source of religious knowledge? Second: What evidence supports the notion that generative AI is a knowledgeable entity in matters of this faith? And third: Have you consulted scholars and obtained their approval to allow generative AI to assume their role?</p>
        <p>Let us take a moment to reflect on the answer to these three questions. First, the credibility of generative AI as a source that can be trusted without doubt. In an interview on a social media platform, Dr. Waleed Kadous, Chief Scientist at Anyscale and a renowned expert in artificial intelligence and machine learning with over fifteen years of experience in Silicon Valley, was asked whether he trusts the information generated by AI. His response was a firm “no.” One of the main reasons he cited was "hallucination."</p>
        <p>“Hallucination” in artificial intelligence refers to the phenomenon where AI systems, particularly large language models (LLMs) like ChatGPT, generate information that appears plausible but is, in fact, incorrect or entirely fabricated. This happens because these models are probabilistic in nature, relying on patterns learned from data without truly understanding the information they generate.</p>
        <p>AI does not know that it does not know. As a result, sometimes, they can “make things up” confidently because they are unaware of their own lack of knowledge. In their blog, OpenAI, the company behind ChatGPT, wrote on November 30, 2022:</p>
<p class="centered-paragraph"><b>“ChatGPT sometimes writes plausible-sounding but incorrect or nonsensical answers.”</b></p>
<p class="centered-paragraph">* * *</p>
        <p></p>
<img id="animated-gif" src="images/AI.gif">
<p class="small-text">Mohd bin Mohd | Month 00, 2025 | 00 Month, 1446</p>

    <div id="pagination">
        <a href="english.html" class="home-button">Back</a>
    </div>

    <div id="night-mode-toggle">
        <label class="switch">
            <input type="checkbox" id="mode-switch">
            <span class="slider"></span>
        </label>
        <span id="mode-label">☀️</span>
    </div>

    <script src="script.js"></script>
</body>
