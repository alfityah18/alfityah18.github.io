<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
    <title>Sheikh GPT</title>
</head>

<body style="display: block; text-align: left;">
    <div class="article-image">
    <img src="images/Eng_06.png" alt="Article Image" style="max-width: 100%;" class="enlargeable-image">
</div>
    
    <article class="article-content">
        <p></p>
<p class="centered-paragraph">* * *</p>
        <p>"Hallucination" in artificial intelligence refers to the phenomenon where AI systems, particularly large language models (LLMs) like ChatGPT, generate information that appears plausible but is, in fact, incorrect or entirely fabricated. This happens because these models are probabilistic in nature, relying on patterns learned from data without truly "understanding" the information they generate.</p>
        <p>AI does not know that it does not know. As a result, sometimes, they can "make things up" confidently because they are unaware of their own lack of knowledge. In their blog, OpenAI, the company behind ChatGPT, wrote on November 30, 2022:</p>
<p class="centered-paragraph"><b>“ChatGPT sometimes writes plausible-sounding but incorrect or nonsensical answers.”</b></p>
<p class="centered-paragraph">* * *</p>
        <p></p>
<img id="animated-gif" src="images/passion.gif">
<p class="small-text">Mohd bin Mohd | Month 00, 2025 | 00 Month, 1446</p>

    <div id="pagination">
        <a href="english.html" class="home-button">Back</a>
    </div>

    <div id="night-mode-toggle">
        <label class="switch">
            <input type="checkbox" id="mode-switch">
            <span class="slider"></span>
        </label>
        <span id="mode-label">☀️</span>
    </div>

    <script src="script.js"></script>
</body>
