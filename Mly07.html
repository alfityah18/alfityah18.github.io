<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
    <title>Syeikh GPT</title>
</head>

<body style="display: block; text-align: left;">
    <div class="article-image">
    <img src="images/Mly_07.png" alt="Article Image" style="max-width: 100%;" class="enlargeable-image">
</div>
    
    <article class="article-content">
        <p></p>
<p class="centered-paragraph">* * *</p>
        <p>“Halusinasi” dalam <i>artificial intelligence</i> merujuk pada fenomena di mana sistem-sistem AI, terutamanya <i>large language models (LLMs)</i> seperti ChatGPT, menghasilkan maklumat yang kelihatan seperti boleh dipercayai tetapi, sebenarnya, salah atau diada-adakan sahaja. Ini berlaku kerana model-model ini bersifat berkebarangkalian, yang bergantung pada corak yang dipelajari daripada data tanpa benar-benar "memahami" maklumat yang ia hasilkan.</p>
        <p>AI tidak tahu yang ia tidak tahu. Akibatnya, kadangkala, ia boleh “memandai-mandai” dengan yakinnya kerana ia tidak sedar tentang kekurangan ilmunya. Dalam blognya, OpenAI, syarikat yang menghasilkan ChatGPT, menulis pada 30 November 2022:</p>
<p class="centered-paragraph"><b>“Kadangkala, ChatGPT menulis jawapan yang kedengaran meyakinkan tetapi sebenarnya salah dan karut.”</b></p>
<p class="centered-paragraph">* * *</p>
        <p></p>
<img id="animated-gif" src="images/AI.gif">
<p class="small-text">Mohd bin Mohd | 00 Bulan, 2025 | 00 Bulan, 1446</p>

    <div id="pagination">
        <a href="bahasa.html" class="home-button">Back</a>
    </div>

    <div id="night-mode-toggle">
        <label class="switch">
            <input type="checkbox" id="mode-switch">
            <span class="slider"></span>
        </label>
        <span id="mode-label">☀️</span>
    </div>

    <script src="script.js"></script>
</body>
