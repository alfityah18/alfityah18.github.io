<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
    <title>Syeikh GPT</title>
</head>

<body style="display: block; text-align: left;">
    <div class="article-image">
    <img src="images/Mly_07.png" alt="Article Image" style="max-width: 100%;" class="enlargeable-image">
</div>
    
    <article class="article-content">
        <p>Dalam artikel pertama yang bertajuk <i>Cabaran Sains & Teknologi,</i> telah dijelaskan bahawa hadith ini merujuk pada kecerdasan buatan atau <i>artificial intelligence</i> (AI). Ia menjadi “makhluk pemangsa” apabila manusia menyalahgunakannya, lalu boleh mendatangkan bahaya kepada individu, masyarakat, mahupun negara. Apabila ia mencapai kematangan serentak dengan perkembangan sains kuantum dan neurologi, suatu hari nanti kita mungkin akan melihat cambuk, tali kasut, dan paha kita betul-betul berkata-kata. الله أعلم.</p>
<p class="centered-paragraph">* * *</p>
        <p>Apa yang ingin difokuskan di sini adalah satu masalah besar yang baru sahaja muncul baru-baru ini, yang boleh membawa bencana kepada umat ini—“Syeikh GPT.” Ini merujuk pada penyalahgunaan <i>generative</i> AI, di mana orang ramai sudah mula bergantung pada alat seperti ChatGPT, Grok, atau Gemini sebagai rujukan agama mereka. Malah, sudah pun ada kandungan agama yang dijanakan sepenuhnya dengan menggunakan alat AI ini, bagi tujuan untuk dijadikan bahan dakwah. Saya telah menyaksikannya di depan mata.</p>
        <p>Kita tidak akan menafikan manfaat yang ada pada teknologi ini. Bahkan, saya sendiri pun menggunakannya. Sebagai seorang yang sibuk antara mencari nafkah dan mendalami ilmu agama, AI telah banyak membantu saya dalam menghasilkan artikel dan video agama. Namun, saya menggunakannya sesuai dengan kadar dan tugas yang sepatutnya sahaja, seperti pembinaan laman web, memperelok terjemahan Bahasa Inggeris, dan penggunaan narator suara AI. Semua ini dapat menjimatkan masa, tenaga, dan wang, terutamanya bagi golongan yang tidak berkemampuan.</p>
        <p>Dalam artikel dan video pertama itu juga telah diperingatkan tentang fitnah yang turut dibawa oleh sebahagian cabang sains dan teknologi. Dan maksud “fitnah” dalam Bahasa Arab Klasik pula telah dihuraikan dalam artikel yang bertajuk <i>Fitnah.</i> Dalam konteks “Syeikh GPT,” fitnah berlaku kerana kecetekan pengetahuan tentang sains dan teknologi, serta kekurangan kefahaman dalam ilmu agama. Dalam Ayat 36 Surah al-Isra, Allah (SWT) berfirman:</p>
<h4>وَلَا تَقۡفُ مَا لَيۡسَ لَكَ بِهِۦ عِلۡمٌۚ</h4>
<p class="centered-paragraph"><b>Janganlah engkau mengikuti apa yang engkau tidak mempunyai pengetahuan (yang pasti) tentangnya.</b></p> 
        <p>Ayat ini mengajar kita akan kepentingan untuk membekalkan diri dengan ilmu yang secukupnya sebelum melibatkan diri dalam sesuatu perkara. Usahlah terburu-buru, kerana sebagaimana sabda Rasulullah ﷺ dalam <i>Musnad Abu Ya’la</i> 4256, sikap terburu-buru itu datangnya daripada syaitan. Dan untuk melengkapkan Ayat Quran itu tadi, kerana pendengaran, penglihatan, dan hati akan diminta pertanggungjawaban.</p>
        <p>Kepada mereka yang telah mengangkat <i>generative</i> AI sebagai “syeikh” mereka, tanyalah dirimu sendiri tiga soalan ini. Pertama: Adakah anda benar-benar mengenali sifat-sifat <i>generative</i> AI sehingga anda boleh menjadikannya sumber rujukan ilmu agama yang diyakini? Kedua: Apakah dalil yang menyokong tanggapan anda bahawa <i>generative</i> AI adalah makhluk yang alim dalam soal agama ini? Dan ketiga: Sudahkah anda merujuk ulama dan mendapatkan kebenaran untuk membenarkan <i>generative</i> AI mengambil alih peranan mereka?</p>
<p class="centered-paragraph">* * *</p>
        <p>Marilah sama-sama kita melihat jawapan kepada tiga soalan ini. Pertama, kredibiliti <i>generative</i> AI sebagai sumber yang boleh diyakini tanpa ragu. Dalam satu wawancara di sebuah platform media sosial, Dr. Waleed Kadous, Ketua Saintis di Anyscale dan seorang pakar yang terkenal dalam bidang kecerdasan buatan dan pembelajaran mesin dengan lebih lima belas tahun pengalaman di Silicon Valley, telah ditanya adakah beliau mempercayai maklumat yang dijanakan oleh AI. Beliau menjawab dengan tegas, “tidak.” Antara sebab utama yang beliau sebutkan adalah “halusinasi.”</p> 
        <p>“Halusinasi” dalam <i>artificial intelligence</i> merujuk pada fenomena di mana sistem-sistem AI, terutamanya <i>large language models</i> (LLMs) seperti ChatGPT, menghasilkan maklumat yang kelihatan seperti boleh dipercayai tetapi, sebenarnya, salah atau diada-adakan sahaja. Ini berlaku kerana model-model ini bersifat berkebarangkalian, yang bergantung pada corak yang dipelajari daripada data tanpa benar-benar memahami maklumat yang ia hasilkan.</p>
        <p>AI tidak tahu yang ia tidak tahu. Akibatnya, kadangkala, ia boleh “memandai-mandai” dengan yakinnya kerana ia tidak sedar tentang kekurangan ilmunya. Dalam blognya, OpenAI, syarikat yang menghasilkan ChatGPT, menulis pada 30 November 2022:</p>
<p class="centered-paragraph"><b>“Kadangkala, ChatGPT menulis jawapan yang kedengaran meyakinkan tetapi sebenarnya salah dan karut.”</b></p>
        <p>Dalam surat berita MIT Technology Review bertajuk <i>It’s Time to Talk About the Real AI Risks,</i> yang diterbitkan oleh Massachusetts Institute of Technology (MIT) pada 12 Jun 2023, pemberita senior Tate Ryan-Mosley menyuarakan kebimbangan tentang isu halusinasi dalam <i>artificial intelligence</i> yang mungkin tidak dapat dibetulkan lagi. Sundar Pichai, CEO Google, dalam satu temu ramah bersama CBS pada 16 April 2023, menyatakan:</p>
<p class="centered-paragraph"><b>“Tiada seorang pun dalam bidang ini yang telah berjaya menyelesaikan masalah halusinasi. Semua model sememangnya menghadapi isu ini.”</b></p>
        <p>Meskipun terdapat pelbagai dakwaan bahawa isu halusinasi dalam AI dapat diatasi, namun setelah bertahun-tahun dan hingga saat artikel ini ditulis, masalah ini tetap belum dapat diselesaikan sepenuhnya. Walaupun terdapat kemajuan dalam data latihan, algoritma, dan kaedah penalaan halus, sistem AI masih boleh menghasilkan maklumat yang tidak tepat dan mengelirukan.</p>
        <p>Kesimpulannya, AI bukanlah sumber rujukan ilmu agama yang boleh diyakini tanpa ragu. Dalam bidang ilmu hadith, apabila seorang perawi didapati pernah berbohong—meskipun pembohongan itu tiada dalam hadithnya yang spesifik—semua riwayat hadithnya diklasifikasikan sebagai “matruk” atau ditinggalkan. Maka, <i>genAI chatbot</i> seperti ChatGPT, Grok, dan Gemini, yang terbukti pernah mereka-reka jawapan serta menjanakan maklumat yang salah, mestilah ditinggalkan apabila ia melibatkan hal ehwal agama.</p>
        <p>Sekarang, mari kita lihat contoh bahaya yang boleh menimpa umat Islam. Meskipun senario ini hanyalah rekaan, ia boleh betul-betul berlaku dalam masyarakat kita.</p>
        <p>X meminta ChatGPT menghasilkan karangan pendek agama, yang kemudiannya disebarkan di media sosial dengan menamakan dirinya sebagai penulisnya. Melihat respons yang positif, X semakin bersemangat untuk menghasilkan lebih banyak lagi. Suatu hari, tanpa disedari—oleh kerana tidak pernah menyemak, malah tidak tahu pun cara-cara membuat semakan kerana tidak pernah belajar agama—X telah menyebarkan sebuah hadith palsu yang direka oleh <i>chatbot</i> itu dengan menyandarkannya kepada Nabi Muhammad ﷺ.</p>
        <p>Baik, mari kita meneliti kesalahan-kesalahan yang dilakukan oleh X.</p> 
        <p>1. Plagiarisme. Dalam <i>Sahih al-Bukhari</i> 6094, Rasulullah ﷺ bersabda: <b>“Pembohongan itu membawa kepada kejahatan, dan kejahatan itu membawa ke neraka.”</b></p>
        <p>2. Sabda Nabi ﷺ dalam <i>Sahih Muslim</i> 5: <b>“Cukuplah seseorang itu dikatakan pembohong apabila dia terus menceritakan apa-apa sahaja yang didengarinya (tanpa menyemak terlebih dahulu).”</b></p>
        <p>3. Ibnu Taymiyyah (RH) dalam <i>Majmu’ al-Fatawa</i> 10/449, berkata: <b>“Sesiapa yang bercakap tentang Islam tanpa ilmu adalah seorang pembohong, meskipun dia tidak berniat untuk berbohong.”</b></p>
        <p>4. Dalam <i>Sahih al-Bukhari</i> 107, Ar-Rasul ﷺ bersabda: <b>“Sesiapa yang berbohong atas namaku, bersiap-siaplah dirinya untuk mengambil tempatnya di dalam neraka.”</b></p>
        <p>5. Apabila orang yang membaca karangannya mengamalkan amalan yang direka-reka. Sabda Al-Mustafa ﷺ dalam <i>Sahih Muslim</i> 1017: <b>“Sesiapa yang memulakan amalan yang buruk dalam Islam, dia akan memikul dosanya dan dosa orang yang mengamalkannya setelahnya, tanpa mengurangi walau sedikit pun dosa mereka.”</b></p>
        <p>Maka, berhati-hatilah.</p>
<p class="centered-paragraph">* * *</p>
        <p>Bagi menjawab soalan kedua—adakah <i>artificial intelligence</i> boleh dianggap sebagai makhluk yang alim dalam soal ilmu agama—kita harus kembali kepada artikel saya yang bertajuk <i>Apabila Ilmu Dibawa Pergi.</i> Selain isu “halusinasi” yang telah dibincangkan, mereka yang telah membaca artikel tersebut dan dikurniakan kefahaman oleh Allah (AWJ), sepatutnya, sudah pun dapat melihat jawapan kepada dilema “Syeikh GPT” ini. Sebelum melanjutkan, mari kita memahami apakah itu AI terlebih dahulu. Marvin Minsky, salah seorang bapa pengasasnya, menerangkan:</p>
<p class="centered-paragraph"><b>“Kecerdasan buatan adalah sains yang membolehkan mesin untuk melakukan perkara yang memerlukan kecerdasan jika ia dilakukan oleh manusia.”</b></p> 
        <p>Ini menekankan bahawa AI melakukan tugasan yang biasanya dikaitkan dengan kecerdasan manusia. Jika kita mengambil kira <i>Oxford Dictionary of English,</i> yang mendefinisikan orang yang berilmu itu sebagai seseorang yang cerdas dan berpengetahuan luas, kita akan mendapati AI juga boleh dianggap sebagai makhluk yang alim. Apakah benar begitu?</p>
        <p>Memandangkan sistem AI seperti ChatGPT, Grok, dan Gemini boleh mengakses maklumat agama yang sangat banyak, menganalisisnya dengan cepat, dan memberikan jawapan yang bermaklumat, maka mereka juga bolehlah dianggap sebagai sumber rujukan agama yang boleh dipercayai. Apakah benar begitu?</p>
        <p>Bagaimana dengan isu “halusinasi”? Jangan risau—bukannya sepanjang masa <i>generative</i> AI memberikan jawapan yang salah dan karut; cuma sekali-sekala sahaja. Lagipun, pada 19 Mac 2024, di Nvidia's GPU Technology Conference di San Jose, Jensen Huang, CEO Nvidia, mengatakan bahawa isu itu “sangat boleh diselesaikan,” melalui suatu proses yang dikenali sebagai RAG, atau <i>“retrieval augmented generation,”</i> yakni penjanaan yang dipertingkatkan dengan pengambilan semula maklumat. Jadi, tidak salah pun kita merujuknya sekiranya kita pandai menilai. Apakah benar begitu?</p>
        <p>Tambahan pula, dalam soal kandungan yang dijanakan sepenuhnya oleh <i>gen-AI chatbot,</i> apa yang penting bukanlah siapa yang menulisnya, tetapi apa yang ditulisnya—apalagi jika ia selari dengan ajaran Al-Quran dan As-Sunnah. Hmm... Sekali lagi, apakah benar begitu?</p>
        <p>Jika hujah-hujah begini datangnya daripada orang awam, kita boleh memahaminya. Tetapi, jika ia datang daripada agamawan ataupun penuntut ilmu agama Islam yang telah menghabiskan masa bertahun-tahun mempelajari ilmu-ilmu Al-Quran dan Hadith, ia adalah perkara yang sangat membimbangkan. Sekilas pandang, hujah-hujah itu seperti ada logiknya. Namun Islam bukanlah agama yang berdasarkan akal, tetapi wahyu. Dalam Ayat 28 Surah Fatir, Tuhan kita berfirman:</p>
<h4>إِنَّمَا يَخْشَى ٱللَّهَ مِنْ عِبَادِهِ ٱلْعُلَمَٰٓؤُا۟</h4>
<p class="centered-paragraph"><b>Sesungguhnya, antara semua hamba-hambaNya, yang benar-benar TAKUT kepada Allah, hanyalah para ulama.</b></p> 
        <p></p>
        <p></p>
        <p></p>
        <p></p>
<p class="centered-paragraph">* * *</p>
        <p></p>
<img id="animated-gif" src="images/AI.gif">
<p class="small-text">Mohd bin Mohd | 00 Bulan, 2025 | 00 Bulan, 1446</p>

    <div id="pagination">
        <a href="bahasa.html" class="home-button">Back</a>
    </div>

    <div id="night-mode-toggle">
        <label class="switch">
            <input type="checkbox" id="mode-switch">
            <span class="slider"></span>
        </label>
        <span id="mode-label">☀️</span>
    </div>

    <script src="script.js"></script>
</body>
